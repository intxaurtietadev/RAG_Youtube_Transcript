{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f0bb814",
   "metadata": {},
   "source": [
    "# RAG\n",
    "\n",
    "A continuación se muestra una descripción general de alto nivel del sistema que queremos construir:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dff98a",
   "metadata": {},
   "source": [
    "<img src='images/img_1.png' width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd650181",
   "metadata": {},
   "source": [
    "# PARTE I"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ad2438",
   "metadata": {},
   "source": [
    "Empecemos cargando las variables de entorno que necesitamos utilizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35475b",
   "metadata": {},
   "source": [
    "## Setting up the model\n",
    "Definamos el modelo LLM que utilizaremos como parte del flujo de trabajo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22ed43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Este es el video de YouTube que vamos a utilizar.\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=aL-EmKuB078&t=2s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef919e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e950151",
   "metadata": {},
   "source": [
    "Probamos el modelo haciendo una pregunta sencilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24d834a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Túnez es Túnez.\n"
     ]
    }
   ],
   "source": [
    "pregunta_sencilla = \"¿Cuál es la capital de Túnez?\"\n",
    "respuesta = model.invoke(pregunta_sencilla)\n",
    "\n",
    "# Imprimimos el contenido de la respuesta\n",
    "print(respuesta.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9c2fea",
   "metadata": {},
   "source": [
    "El resultado del modelo es una instancia de `AIMessage` que contiene la respuesta. Podemos extraer esta respuesta encadenando el modelo con un analizador de salida [outputParser](https://python.langchain.com/docs/modules/model_io/output_parsers/).\n",
    "\n",
    "Así es como se ve el encadenamiento del modelo con un analizador de salida:\n",
    "\n",
    "<img src='images/chain1.png' width=\"1200\">\n",
    "\n",
    "Para este ejemplo, utilizaremos un `StrOutputParser` simple para extraer la respuesta como una cadena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0beeb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La capital de Alemania es Berlín.\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#(convertir AIMessage a string)\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# Creamos la cadena simple combinando el modelo y el parser\n",
    "chain = model | parser\n",
    "\n",
    "# Probamos la cadena con la misma pregunta sencilla\n",
    "pregunta_sencilla = \"¿Cuál es la capital de Alemaña?\"\n",
    "respuesta_parseada = chain.invoke(pregunta_sencilla)\n",
    "\n",
    "# Imprimimos la respuesta (ahora debería ser una cadena directamente)\n",
    "print(respuesta_parseada)\n",
    "print(type(respuesta_parseada)) # Para verificar que es un string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e848d0",
   "metadata": {},
   "source": [
    "## Presentamos las plantillas de preguntas\n",
    "\n",
    "Queremos contextualizar el modelo y la pregunta. [Prompt templates](https://python.langchain.com/docs/modules/model_io/prompts/quick_start) Son una forma sencilla de definir y reutilizar indicaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "Responda la pregunta según el contexto descrito a continuación. Si no puede responder, responda \"No lo sé\".\n",
    "\n",
    "Contexto: {contexto}\n",
    "\n",
    "Pregunta: {pregunta}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4100f1a9",
   "metadata": {},
   "source": [
    "Ahora podemos encadenar el mensaje con el modelo y el analizador de salida.\n",
    "\n",
    "<img src='images/chain2.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2eb9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos RunnablePassthrough que permite pasar datos sin modificarlos a través de la cadena\n",
    "from langchain_core.runnables import  RunnablePassthrough\n",
    "\n",
    "# Definimos la cadena de procesamiento que consta de varios componentes\n",
    "chain = (\n",
    "   # Creamos un diccionario con dos entradas que serán los inputs de la cadena\n",
    "        {\n",
    "            \"contexto\": RunnablePassthrough(),\n",
    "            \"pregunta\": RunnablePassthrough()\n",
    "        }\n",
    "        # El operador | conecta los componentes de la cadena en secuencia\n",
    "        # Toma el template definido anteriormente y formatea el mensaje usando los valores de \"contexto\" y \"pregunta\"\n",
    "        | ChatPromptTemplate.from_template(template)\n",
    "        # Aplicamos la plantilla de prompt para generar el prompt completo\n",
    "        | model\n",
    "        # Aplicamos el parser para convertir la respuesta a string\n",
    "        | parser\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11f36b2",
   "metadata": {},
   "source": [
    "## Combinación de cadenas\n",
    "\n",
    "Podemos combinar diferentes cadenas para crear flujos de trabajo más complejos. Por ejemplo, creemos una segunda cadena que traduzca la respuesta de la primera a otro idioma.\n",
    "\n",
    "Comencemos creando una nueva plantilla de solicitud para la cadena de traducción:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc59531b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Traduce {answer} al {language}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1276e2fb",
   "metadata": {},
   "source": [
    "Ahora podemos crear una nueva cadena de traducción que combine el resultado de la primera cadena con la solicitud de traducción.\n",
    "\n",
    "Así es como se ve el nuevo flujo de trabajo:\n",
    "\n",
    "<img src='images/chain3.png' width=\"1200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5079dc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta traducida: Translate {'answer': 'The capital of France is Paris.', 'language': 'Spanish'} to English\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Cadena de respuesta usando contexto (primera cadena, ya definida anteriormente)\n",
    "qa_chain = (\n",
    "    {\n",
    "        \"contexto\": RunnablePassthrough(),\n",
    "        \"pregunta\": RunnablePassthrough()\n",
    "    }\n",
    "    | ChatPromptTemplate.from_template(template)\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Crear la cadena de traducción\n",
    "translation_chain = (\n",
    "    {\n",
    "        \"answer\": RunnablePassthrough(),\n",
    "        \"language\": lambda _: \"Inglés\"  # valor predeterminado\n",
    "    }\n",
    "    | translation_prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Combinamos ambas cadenas: primero obtenemos la respuesta, luego la traducimos\n",
    "combined_chain = qa_chain | (lambda answer: translation_chain.invoke({\"answer\": answer, \"language\": \"Castellano\"}))\n",
    "\n",
    "# Probemos la cadena combinada\n",
    "respuesta_traducida = combined_chain.invoke({\n",
    "    \"contexto\": \"Paris es la capital de Francia y una de las ciudades más visitadas del mundo.\",\n",
    "    \"pregunta\": \"¿Cuál es la capital de Francia?\"\n",
    "})\n",
    "\n",
    "print(\"Respuesta traducida:\", respuesta_traducida)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a226673",
   "metadata": {},
   "source": [
    "# PARTE II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0366ee9",
   "metadata": {},
   "source": [
    "## Transcripcion de video de YouTube\n",
    "\n",
    "El contexto que queremos enviar al modelo proviene de un video de YouTube. Descargamos el video y transcribámoslo con [OpenAI's Whisper](https://openai.com/research/whisper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db966556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription file already exists!\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "import os\n",
    "import yt_dlp  # Usando yt-dlp en lugar de pytube\n",
    "\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    print(f\"Descargando video: {YOUTUBE_VIDEO}\")\n",
    "    \n",
    "    # Crear un directorio temporal para la descarga\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        # Opciones de yt-dlp para descargar solo el audio\n",
    "        ydl_opts = {\n",
    "            'format': 'bestaudio/best',\n",
    "            'outtmpl': os.path.join(tmpdir, 'audio.%(ext)s'),\n",
    "            'postprocessors': [{\n",
    "                'key': 'FFmpegExtractAudio',\n",
    "                'preferredcodec': 'mp3',\n",
    "                'preferredquality': '192',\n",
    "            }],\n",
    "            'quiet': False\n",
    "        }\n",
    "        \n",
    "        # Descargar el audio\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.extract_info(YOUTUBE_VIDEO, download=True)\n",
    "            audio_file = os.path.join(tmpdir, 'audio.mp3')\n",
    "        \n",
    "        print(f\"Transcribiendo archivo de audio: {audio_file}\")\n",
    "        \n",
    "        # Cargar el modelo Whisper\n",
    "        whisper_model = whisper.load_model(\"base\")\n",
    "        \n",
    "        # Transcribir el audio\n",
    "        transcription = whisper_model.transcribe(audio_file, fp16=False)[\"text\"].strip()\n",
    "        \n",
    "        # Guardar la transcripción en un archivo\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)\n",
    "        \n",
    "        print(\"Transcription completed and saved to 'transcription.txt'\")\n",
    "else:\n",
    "    print(\"Transcription file already exists!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04e1c9e",
   "metadata": {},
   "source": [
    "Vamos a leer la transcripción y mostrar los primeros caracteres para asegurarnos de que todo funciona como se espera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09313d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What's really happening in Antarctica? Why was the entire continent suddenly locked down after a US \""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"transcription.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "transcription[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7897a",
   "metadata": {},
   "source": [
    "## Usando la transcripción completa como contexto\n",
    "\n",
    "Si intentamos invocar la cadena usando la transcripción como contexto, el modelo devolverá un error porque el contexto es demasiado largo.\n",
    "\n",
    "Los modelos de lenguaje grandes admiten tamaños de contexto limitados. El vídeo que estamos usando es demasiado largo para que el modelo lo pueda procesar, por lo que necesitamos buscar una solución diferente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70fd63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respuesta: No lo sé.\n"
     ]
    }
   ],
   "source": [
    "# Primero, aseguramos que tengamos la transcripción cargada\n",
    "with open(\"transcription.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "# Ahora intentamos usar la transcripción como contexto\n",
    "try:\n",
    "    # Guardamos la respuesta en una variable\n",
    "    respuesta = chain.invoke({\n",
    "        # Corregimos \"context\" a \"contexto\" para que coincida con el template\n",
    "        \"contexto\": transcription,\n",
    "        \"pregunta\": \"¿Es una buena idea leer artículos?\"\n",
    "    })\n",
    "    # Imprimimos la respuesta si es exitosa\n",
    "    print(\"Respuesta:\", respuesta)\n",
    "    \n",
    "except Exception as e:\n",
    "    # Imprimimos información más detallada del error\n",
    "    print(\"Error al procesar la transcripción:\")\n",
    "    print(e)\n",
    "    print(\"\\nEsto probablemente ocurre porque el texto es demasiado largo para el contexto del modelo.\")\n",
    "    print(\"Considera usar la división de texto (text splitting) para manejar documentos largos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a670c23f",
   "metadata": {},
   "source": [
    "## División de la transcripción\n",
    "\n",
    "Dado que no podemos usar la transcripción completa como contexto para el modelo, una posible solución es dividir la transcripción en fragmentos más pequeños. Así, podemos invocar el modelo utilizando solo los fragmentos relevantes para responder a una pregunta específica:\n",
    "\n",
    "<img src='images/system2.png' width=\"1200\">\n",
    "\n",
    "Comencemos cargando la transcripción en la memoria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553031dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document\n",
      "Text length: 17825 characters\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "# Cargamos el archivo de transcripción usando el cargador de texto de LangChain\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Imprimimos información básica sobre el documento cargado\n",
    "print(f\"Loaded {len(documents)} document\")\n",
    "print(f\"Text length: {len(documents[0].page_content)} characters\")\n",
    "\n",
    "# Esto nos ayuda a verificar que la carga fue exitosa y conocer el tamaño del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af1708a",
   "metadata": {},
   "source": [
    "Hay muchas maneras de dividir un documento. En este ejemplo, usaremos un divisor simple que divide el documento en fragmentos de tamaño fijo. Consulta [Divisores de texto](https://python.langchain.com/docs/modules/data_connection/document_transformers/) para obtener más información sobre los diferentes enfoques para dividir documentos.\n",
    "\n",
    "A modo de ejemplo, dividiremos la transcripción en fragmentos de 100 caracteres con una superposición de 20 caracteres y mostraremos los primeros fragmentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003fbfaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the document into 223 chunks\n",
      "\n",
      "First three chunks:\n",
      "\n",
      "Chunk 1:\n",
      "Length: 99 characters\n",
      "Content: What's really happening in Antarctica? Why was the entire continent suddenly locked down after a US\n",
      "\n",
      "Chunk 2:\n",
      "Length: 95 characters\n",
      "Content: down after a US drone captured something no one was ever supposed to see? Stick around. Because\n",
      "\n",
      "Chunk 3:\n",
      "Length: 98 characters\n",
      "Content: around. Because what we're about to uncover might change everything you thought you knew about the\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Primero cargamos el documento\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "documents = loader.load()\n",
    "\n",
    "# Creamos un divisor de texto con tamaño de fragmento de 100 y superposición de 20 caracteres\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=100,# Tamaño de cada fragmento\n",
    "    chunk_overlap=20,# Cantidad de caracteres que se solapan entre fragmentos\n",
    "    length_function=len,# Función para medir la longitud del texto\n",
    ")\n",
    "\n",
    "# Dividimos el documento en fragmentos\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Mostramos información sobre los fragmentos generados\n",
    "print(f\"Split the document into {len(chunks)} chunks\")\n",
    "\n",
    "# Mostramos los primeros 3 fragmentos como ejemplo\n",
    "print(\"\\nFirst three chunks:\")\n",
    "for i, chunk in enumerate(chunks[:3]):\n",
    "    print(f\"\\nChunk {i+1}:\")\n",
    "    print(f\"Length: {len(chunk.page_content)} characters\")\n",
    "    print(f\"Content: {chunk.page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c52723",
   "metadata": {},
   "source": [
    "Para nuestra aplicación específica, utilizaremos 1000 caracteres en su lugar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdc86c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split the document into 23 chunks\n",
      "\n",
      "First chunk:\n",
      "Length: 999 characters\n",
      "Content: What's really happening in Antarctica? Why was the entire continent suddenly locked down after a US drone captured something no one was ever supposed to see? Stick around. Because what we're about to uncover might change everything you thought you knew about the icy depths of our planet. In January of 2018, an email from a retired naval flight engineer who went by the name of Brian revealed that a US drone had flown over the frozen wasteland of Antarctica and captured something that no one was ever supposed to see. A massive, glowing hole in the ice perfectly round in shape exposed something mysterious beneath the surface. Within hours the entire continent was placed under an immediate lockdown and those who dared to talk about it vanished without a trace. Brian had spent years flying over Antarctica, logging thousands of hours in the sky. But there was one flight in the late 1980s that stood out among all the others, a flight that altered his life forever. As his aircraft soared high\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Creamos un divisor de texto con tamaño de fragmento de 1000 y superposición de 200 caracteres\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len,\n",
    ")\n",
    "\n",
    "# Dividimos el documento en fragmentos\n",
    "chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "# Mostramos información sobre los fragmentos\n",
    "print(f\"Split the document into {len(chunks)} chunks\")\n",
    "\n",
    "# Mostramos el primer fragmento como ejemplo\n",
    "if chunks:\n",
    "    print(\"\\nFirst chunk:\")\n",
    "    print(f\"Length: {len(chunks[0].page_content)} characters\")\n",
    "    print(f\"Content: {chunks[0].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9ec49f",
   "metadata": {},
   "source": [
    "# PARTE III"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad8f794",
   "metadata": {},
   "source": [
    "## Configuración de un Vector Store\n",
    "\n",
    "Necesitamos una forma eficiente de almacenar fragmentos de documentos, sus Embeddings y realizar búsquedas de similitud a gran escala. Para ello, usaremos un Vector Store.\n",
    "\n",
    "Un Vector Store es una base de datos de Embeddings especializada en búsquedas rápidas de similitud.\n",
    "\n",
    "\n",
    "<img src='images/chain4.png' width=\"1200\">\n",
    "\n",
    "Necesitamos configurar un retriever (https://python.langchain.com/docs/how_to/#retrievers). Este retriever realizará una búsqueda de similitud en el almacén vectorial y devolverá los documentos más similares al siguiente paso de la cadena."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44af54dd",
   "metadata": {},
   "source": [
    "## Configurar Pinecone\n",
    "\n",
    "Para este ejemplo, usaremos [Pinecone](https://www.pinecone.io/).\n",
    "\n",
    "<img src=\"images/pinecone.png\" width=\"800\">\n",
    "\n",
    "El primer paso es crear una cuenta de Pinecone, configurar un índice, obtener una clave API y configurarla como variable de entorno `PINECONE_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb82458e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oussama/dev/RAG_Presentation/rag-from-scracht/venv/lib/python3.11/site-packages/pinecone/data/index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eliminating existing index 'rag-transcription' to recreate with correct dimensions\n",
      "Created new index 'rag-transcription' with dimension 384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/0425_ksd7gl2jnqxhr8qwwhw0000gn/T/ipykernel_83242/2696955245.py:36: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 23 chunks into Pinecone index 'rag-transcription'\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import os\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "# Inicializamos Pinecone\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "# Creamos el cliente de Pinecone\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "# Creamos el nombre del índice\n",
    "index_name = \"rag-transcription\"\n",
    "\n",
    "# Si el índice existe, lo eliminamos primero para recrearlo con la dimensión correcta\n",
    "if index_name in pc.list_indexes().names():\n",
    "    print(f\"Eliminating existing index '{index_name}' to recreate with correct dimensions\")\n",
    "    pc.delete_index(index_name)\n",
    "    # Esperamos un momento para que la eliminación se complete\n",
    "    import time\n",
    "    time.sleep(5)\n",
    "\n",
    "# Creamos el índice con las dimensiones correctas\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=384,  # HuggingFace 'all-MiniLM-L6-v2' embeddings tienen 384 dimensiones\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    )\n",
    ")\n",
    "print(f\"Created new index '{index_name}' with dimension 384\")\n",
    "\n",
    "# Inicializamos el modelo de embeddings de HuggingFace (no necesita clave API, se ejecuta localmente)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Creamos el vector store y cargamos los documentos\n",
    "vectorstore = PineconeVectorStore.from_documents(\n",
    "    documents=chunks,  # Usamos los fragmentos creados anteriormente\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")\n",
    "\n",
    "print(f\"Successfully loaded {len(chunks)} chunks into Pinecone index '{index_name}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9d2b3e",
   "metadata": {},
   "source": [
    "Ahora ejecutemos una búsqueda de similitud en pinecone para asegurarnos de que todo funciona:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3a2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for query: What are the main topics discussed in the video?\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 1:\n",
      "forever. Be from Brian's encounter with the glowing hole in the ice to the lost testimonies of Admiral Bird and the frightening reports of military suppression, it's clear that there's far more beneath the surface of this icy continent than meets the eye. What do you think is really going on in Antarctica? What do you believe is being concealed beneath the ice and why? Could it be something extraterrestrial, an ancient civilization, or a government cover-up that stretches beyond imagination? If you enjoyed today's video, please give it a like and don't forget to subscribe to the channel. Your support means a lot to us. Click on the video that appears on your screen right now. I'm sure you'll love this content. Comment below about the next topic you'd like to see featured on our channel. Thank you so much for watching and we'll see you in the next video. Thanks for being with us, leave a comment, like to show your support, and remember to hit that subscribe button for more exciting\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 2:\n",
      "Thank you so much for watching and we'll see you in the next video. Thanks for being with us, leave a comment, like to show your support, and remember to hit that subscribe button for more exciting videos. See you next time.\n",
      "--------------------------------------------------\n",
      "\n",
      "Result 3:\n",
      "Antarctica, logging thousands of hours in the sky. But there was one flight in the late 1980s that stood out among all the others, a flight that altered his life forever. As his aircraft soared high over the icy expanse, Brian and his crew noticed something unusual below. A massive, perfect circle cut into the ice and within that circle a strange, glowing cave appeared to lie beneath the surface. Before they could get any closer, chaos erupted. The plane's navigation system shut down, communication equipment weren't haywire and the aircraft itself became difficult to control. With no other option, Brian's crew had to abandon the mission and head back to base. When they landed, they were met by a group of serious-looking men in dark suits. Every single record of their flight was confiscated and Brian was given a stern warning. Never speak of what they had witnessed. This incident wasn't just an anomaly. It marked the beginning of a string of strange government-mandated cover-ups that\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Prueba de búsqueda por similitud\n",
    "query = \"What are the main topics discussed in the video?\"\n",
    "docs = vectorstore.similarity_search(query, k=3)# Recupera los 3 fragmentos más similares\n",
    "\n",
    "print(\"\\nResults for query:\", query)\n",
    "print(\"-\" * 50)\n",
    "for i, doc in enumerate(docs, 1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(doc.page_content)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3fe01f",
   "metadata": {},
   "source": [
    "Configuremos la nueva cadena usando Pinecone como almacén vectorial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What are the key points discussed in the video?\n",
      "\n",
      "Answer: The key points discussed in the video include Brian's encounter with a glowing hole in the ice, lost testimonies of Admiral Bird, frightening reports of military suppression, the possibility of something extraterrestrial, an ancient civilization, or a government cover-up in Antarctica. The video also mentions mysterious dark shapes moving inside the glowing hole, malfunctioning systems on aircraft, military response to the coded message about the hole, and Brian's questioning by a secret government agency.\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Crear la plantilla del prompt\n",
    "template = \"\"\"Answer the following question based on the provided context:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer the question based on the context provided. If you cannot find the answer in the context, say so.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# Crear la cadena RAG\n",
    "model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# Crear los componentes de la cadena\n",
    "chain = (\n",
    "    RunnableParallel(\n",
    "        context=lambda x: vectorstore.similarity_search(x[\"question\"], k=3),\n",
    "        question=RunnablePassthrough()\n",
    "    )\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# # Probar la cadena\n",
    "question = \"What are the key points discussed in the video?\"\n",
    "response = chain.invoke({\"question\": question})\n",
    "print(\"\\nQuestion:\", question)\n",
    "print(\"\\nAnswer:\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
